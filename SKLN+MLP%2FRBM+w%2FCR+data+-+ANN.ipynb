{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPM (Other People's Machine)\n",
    "### ... learning libraries\n",
    "\n",
    "Well, it is not about Other People's Money that I am talking about here. There are many open source libraries available, including Deep Learning libraries that you can call in for your rather complex ANN models. Why not we do the OPM for ANN? \n",
    "\n",
    "Welcome to MACHINE LEARNING! Below is a simple introductory example of how easy for you to load your data and run a simple neural networks using Scikit Learn.\n",
    "\n",
    "\n",
    "## Credit Default Prediction with Neural Networks\n",
    "In this notebook, I used a sample credit card data to predict write-off prediction using a simple neural networks.  Deep-learning is gaining great momentum these days as those enable users to tackle various modeling challenges that we were not able to easily address such as image recognition.  Yet, there are many applicable techniques for financial services and I hope you can see how easy it is to adopt this deep learning technique for a real business problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "Neural Networks are a machine learning framework that attempts to mimic the learning pattern of natural biological neural networks. Biological neural networks have interconnected neurons with dendrites that receive inputs, then based on these inputs they produce an output signal through an axon to another neuron. Data scientists tried to mimic this process through the use of Artificial Neural Networks (ANN). The process of creating a neural network begins with the most basic form, a single perceptron. \n",
    "\n",
    "## MLP (Multi-Layer Perceptron)\n",
    "\n",
    "A perceptron has one or more inputs, a bias, an activation function, and a single output. The perceptron receives inputs, multiplies them by some weight, and then passes them into an activation function to produce an output. There are many possible activation functions to choose from, such as the logistic function, a trigonometric function, a step function etc. We also make sure to add a bias to the perceptron, this avoids issues where all inputs could be equal to zero (meaning no multiplicative weight would have an effect).\n",
    "\n",
    "Once we have the output we can compare it to a known label and adjust the weights accordingly (the weights usually start off with random initialization values). We keep repeating this process until we have reached a maximum number of allowed iterations, or an acceptable error rate.\n",
    "\n",
    "To create a neural network, we simply begin to add layers of perceptrons together, creating a multi-layer perceptron model of a neural network. You'll have an input layer which directly takes in your feature inputs and an output layer which will create the resulting outputs. Any layers in between are known as hidden layers because they don't directly \"see\" the feature inputs or outputs.\n",
    "\n",
    "Towards the end, I will briefly introduce Restricted Boltzman Machine (RBM) that is another example of simple and shallow ANN.\n",
    "\n",
    "Need more details on MLP? you want to check out on [wikipedia](https://en.wikipedia.org/wiki/Multilayer_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <th>PROD</th>\n",
       "      <th>CURR_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>CUST_INC</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>PMT_DUE</th>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <th>FICO_SCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>755.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44212</td>\n",
       "      <td>46</td>\n",
       "      <td>60.41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1292</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>276.61</td>\n",
       "      <td>0.7</td>\n",
       "      <td>86249</td>\n",
       "      <td>34</td>\n",
       "      <td>22.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1293</td>\n",
       "      <td>2.GOLD</td>\n",
       "      <td>424.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79474</td>\n",
       "      <td>45</td>\n",
       "      <td>21.23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294</td>\n",
       "      <td>3.PLAT</td>\n",
       "      <td>11683.23</td>\n",
       "      <td>10.8</td>\n",
       "      <td>81198</td>\n",
       "      <td>58</td>\n",
       "      <td>584.16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>246.34</td>\n",
       "      <td>5.5</td>\n",
       "      <td>63502</td>\n",
       "      <td>35</td>\n",
       "      <td>19.71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ACCT_NO    PROD  CURR_BAL  TENURE  CUST_INC  CUST_AGE  PMT_DUE  NO_DM_CNT  \\\n",
       "0      1291   1.REG    755.16     3.0     44212        46    60.41          5   \n",
       "1      1292   1.REG    276.61     0.7     86249        34    22.13         10   \n",
       "2      1293  2.GOLD    424.70     0.1     79474        45    21.23         22   \n",
       "3      1294  3.PLAT  11683.23    10.8     81198        58   584.16         22   \n",
       "4      1295   1.REG    246.34     5.5     63502        35    19.71         11   \n",
       "\n",
       "   WRITE_OFF_IND  FICO_SCR  \n",
       "0              1       651  \n",
       "1              0       702  \n",
       "2              0       753  \n",
       "3              0       763  \n",
       "4              1       590  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/YLEE200/MLFS/master/testdata/CRPMT_SAMPLE.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <td>610</td>\n",
       "      <td>1595.500000</td>\n",
       "      <td>176.236111</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>1443.2500</td>\n",
       "      <td>1595.500</td>\n",
       "      <td>1747.7500</td>\n",
       "      <td>1900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CURR_BAL</th>\n",
       "      <td>610</td>\n",
       "      <td>1804.107770</td>\n",
       "      <td>2905.286132</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>331.7525</td>\n",
       "      <td>680.625</td>\n",
       "      <td>1049.4625</td>\n",
       "      <td>11996.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TENURE</th>\n",
       "      <td>610</td>\n",
       "      <td>6.432459</td>\n",
       "      <td>4.634506</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>5.900</td>\n",
       "      <td>8.9000</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_INC</th>\n",
       "      <td>610</td>\n",
       "      <td>83260.531148</td>\n",
       "      <td>42206.490438</td>\n",
       "      <td>25089.0</td>\n",
       "      <td>54015.5000</td>\n",
       "      <td>73585.500</td>\n",
       "      <td>94804.2500</td>\n",
       "      <td>217338.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_AGE</th>\n",
       "      <td>610</td>\n",
       "      <td>40.132787</td>\n",
       "      <td>11.691593</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>69.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMT_DUE</th>\n",
       "      <td>610</td>\n",
       "      <td>99.196262</td>\n",
       "      <td>142.255957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.6625</td>\n",
       "      <td>46.400</td>\n",
       "      <td>78.4625</td>\n",
       "      <td>599.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <td>610</td>\n",
       "      <td>9.870492</td>\n",
       "      <td>6.714781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <td>610</td>\n",
       "      <td>0.150820</td>\n",
       "      <td>0.358167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FICO_SCR</th>\n",
       "      <td>610</td>\n",
       "      <td>701.326230</td>\n",
       "      <td>85.151137</td>\n",
       "      <td>551.0</td>\n",
       "      <td>625.0000</td>\n",
       "      <td>693.500</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>849.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean           std      min         25%  \\\n",
       "﻿ACCT_NO         610   1595.500000    176.236111   1291.0   1443.2500   \n",
       "CURR_BAL         610   1804.107770   2905.286132    -25.0    331.7525   \n",
       "TENURE           610      6.432459      4.634506      0.1      2.8000   \n",
       "CUST_INC         610  83260.531148  42206.490438  25089.0  54015.5000   \n",
       "CUST_AGE         610     40.132787     11.691593     19.0     31.0000   \n",
       "PMT_DUE          610     99.196262    142.255957      0.0     22.6625   \n",
       "NO_DM_CNT        610      9.870492      6.714781      1.0      4.0000   \n",
       "WRITE_OFF_IND    610      0.150820      0.358167      0.0      0.0000   \n",
       "FICO_SCR         610    701.326230     85.151137    551.0    625.0000   \n",
       "\n",
       "                     50%         75%        max  \n",
       "﻿ACCT_NO        1595.500   1747.7500    1900.00  \n",
       "CURR_BAL         680.625   1049.4625   11996.61  \n",
       "TENURE             5.900      8.9000      22.00  \n",
       "CUST_INC       73585.500  94804.2500  217338.00  \n",
       "CUST_AGE          40.000     49.0000      69.00  \n",
       "PMT_DUE           46.400     78.4625     599.83  \n",
       "NO_DM_CNT          7.000     15.0000      26.00  \n",
       "WRITE_OFF_IND      0.000      0.0000       1.00  \n",
       "FICO_SCR         693.500    780.0000     849.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labeling and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <th>PROD</th>\n",
       "      <th>CURR_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>CUST_INC</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>PMT_DUE</th>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <th>FICO_SCR</th>\n",
       "      <th>PROD_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>755.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44212</td>\n",
       "      <td>46</td>\n",
       "      <td>60.41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1292</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>276.61</td>\n",
       "      <td>0.7</td>\n",
       "      <td>86249</td>\n",
       "      <td>34</td>\n",
       "      <td>22.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1293</td>\n",
       "      <td>2.GOLD</td>\n",
       "      <td>424.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79474</td>\n",
       "      <td>45</td>\n",
       "      <td>21.23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294</td>\n",
       "      <td>3.PLAT</td>\n",
       "      <td>11683.23</td>\n",
       "      <td>10.8</td>\n",
       "      <td>81198</td>\n",
       "      <td>58</td>\n",
       "      <td>584.16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>246.34</td>\n",
       "      <td>5.5</td>\n",
       "      <td>63502</td>\n",
       "      <td>35</td>\n",
       "      <td>19.71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ACCT_NO    PROD  CURR_BAL  TENURE  CUST_INC  CUST_AGE  PMT_DUE  NO_DM_CNT  \\\n",
       "0      1291   1.REG    755.16     3.0     44212        46    60.41          5   \n",
       "1      1292   1.REG    276.61     0.7     86249        34    22.13         10   \n",
       "2      1293  2.GOLD    424.70     0.1     79474        45    21.23         22   \n",
       "3      1294  3.PLAT  11683.23    10.8     81198        58   584.16         22   \n",
       "4      1295   1.REG    246.34     5.5     63502        35    19.71         11   \n",
       "\n",
       "   WRITE_OFF_IND  FICO_SCR  PROD_NO  \n",
       "0              1       651        0  \n",
       "1              0       702        0  \n",
       "2              0       753        1  \n",
       "3              0       763        2  \n",
       "4              1       590        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# converting PROD to numerical (0: 1.REG, 1: 2.GOLD, 2: 3.PLAT)\n",
    "lenc = LabelEncoder()\n",
    "lenc.fit(df['PROD'])\n",
    "\n",
    "df['PROD_NO'] = lenc.transform(df['PROD'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all numeric feature variables \n",
    "\n",
    "feature_cols = [\n",
    "    'CURR_BAL',                                               \n",
    "    'TENURE',                       \n",
    "    'CUST_INC',                      \n",
    "    'CUST_AGE',                                \n",
    "    'PMT_DUE',                                               \n",
    "    'NO_DM_CNT',               \n",
    "    'FICO_SCR',\n",
    "    'PROD_NO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CURR_BAL     float64\n",
       "TENURE       float64\n",
       "CUST_INC       int64\n",
       "CUST_AGE       int64\n",
       "PMT_DUE      float64\n",
       "NO_DM_CNT      int64\n",
       "FICO_SCR       int64\n",
       "PROD_NO        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_cols]\n",
    "y = df.WRITE_OFF_IND\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results. There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Multi-Layer Perceptron Classifier Model (MLP)\n",
    "\n",
    "Now it is time to train our model. SciKit Learn makes this incredibly easy, by using estimator objects. In this case we will import our estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(13, 13, 13), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluation\n",
    "\n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128   5]\n",
      " [ 19   1]]\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       133\n",
      "          1       0.17      0.05      0.08        20\n",
      "\n",
      "avg / total       0.78      0.84      0.80       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! This is pretty good considering how few lines of code we had to write. The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
    "\n",
    "However, if you do want to extract the MLP weights and biases after training your model, you use its public attributes coefs_ and intercepts_.\n",
    "\n",
    "coefs_ is a list of weight matrices, where weight matrix at index i represents the weights between layer i and layer i+1.\n",
    "\n",
    "intercepts_ is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.coefs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.intercepts_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Restricted Boltzman Machine (RBM)\n",
    "> from [wikipedia - RBM](https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine)\n",
    "\n",
    "A restricted Boltzmann machine (RBM) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs. Invented by Geoff Hinton, a Restricted Boltzmann machine is an algorithm useful for dimensionality reduction, classification, regression, collaborative filtering, feature learning and topic modeling. RBMs are shallow, two-layer neural nets that constitute the building blocks of deep-belief networks. The first layer of the RBM is called the visible, or input, layer, and the second is the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=2, n_iter=10,\n",
       "       random_state=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "\n",
    "rbm = BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=2, n_iter=10, random_state=None, verbose=0)\n",
    "\n",
    "rbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128   5]\n",
      " [ 19   1]]\n"
     ]
    }
   ],
   "source": [
    "rbm_pred = mlp.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,rbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       133\n",
      "          1       0.17      0.05      0.08        20\n",
      "\n",
      "avg / total       0.78      0.84      0.80       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rbm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "This illustrative python notebook shows how to get started with a simple Neural Networks utilizing MLP and RBM techniques.  I hope you to see how easy to adopt machine learning for your data analytics and modeling needs.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
