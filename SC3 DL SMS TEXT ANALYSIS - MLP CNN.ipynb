{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING FOR FINANCIAL SERVICES\n",
    "\n",
    "Welcome to IBM's Data Science Experience! This exciting tool will help your life a lot easier as a data scientist. Below is a simple introductory example of how easy for you to load your data and run deep learning algorithms to analyze and predict an outcome.\n",
    "\n",
    "## Deep Learning for Text Analysis \n",
    "Approximately, 85% of the data is unstructured and those who can unleash the powerful insights from those will, no doubt, create a superior competitive advantage.   In this notebook, I chose a sample hypothetical SMS data to predict churn response by training simple Neural Network algorithms (MLP and 1-D CNN) using Keras library. Especially, CNN (Convolutional Neural Networks) is being employed in high dimensional computations such as image recognition , yet I'd like to introduce a basic/simple Natural Language Processing (NLP) for illustrative purpose. \n",
    "\n",
    "> Natural Language Processing (NLP): NLP is a way for computers to analyze, understand, and derive meaning from human language in a smart and useful way. By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation.  \n",
    "\n",
    "> Although NLP could get very complex, in a nutshell, the data (text or speech) needs to be \"parameterized\" (or making the data to \"numbers\") so that machine learning algorithms can kicks in and do the magics :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# @hidden_cell\n",
    "# This function accesses a file in your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def get_object_storage_file_with_credentials_fcf1c90868844bc1ab7d4fffe6063140(container, filename):\n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': 'member_cf2f28cf1cf37485c31a0c2d2443463e000ad9b0','domain': {'id': '20b49a5877434f9486aa2a1d2fcdd21c'},\n",
    "            'password': 'tVP(ZWG8k9J._ZhB'}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return StringIO(resp2.text)\n",
    "\n",
    "data_1 = get_object_storage_file_with_credentials_fcf1c90868844bc1ab7d4fffe6063140('MachineLearningShowcase', 'churnSMS.csv')\n",
    "sms = pd.read_table(data_1, header=None, sep = \",\", names=['label', 'message'])\n",
    "\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you like to directly read in from my github...\n",
    "\n",
    "#import pandas as pd\n",
    "#url = 'https://raw.githubusercontent.com/YLEE200/ML-SHOWCASE/master/churnSMS.csv'\n",
    "\n",
    "#sms = pd.read_csv(url, names =['label', 'message'], encoding='iso-8859-1')\n",
    "#sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datactr1</td>\n",
       "      <td>cofidential and proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>churn</td>\n",
       "      <td>this is interesting� please cancel my policy n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>churn</td>\n",
       "      <td>would you call me ASAP?  My number is 123-555-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>churn</td>\n",
       "      <td>I am not renewing my policy. This is sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>churn</td>\n",
       "      <td>there has been a fraud on my account. please c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>churn</td>\n",
       "      <td>OMG, I don't like this�. I am done w/ my account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>churn</td>\n",
       "      <td>FRAUD, for god sake.. What is going on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>churn</td>\n",
       "      <td>Too expensive!  There should be some discount�.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>churn</td>\n",
       "      <td>My friend told me, there�s a better deal out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>churn</td>\n",
       "      <td>Can you believe it? Cancel my account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message\n",
       "0  datactr1                        cofidential and proprietary\n",
       "1     churn  this is interesting� please cancel my policy n...\n",
       "2     churn  would you call me ASAP?  My number is 123-555-...\n",
       "3     churn         I am not renewing my policy. This is sucks\n",
       "4     churn  there has been a fraud on my account. please c...\n",
       "5     churn   OMG, I don't like this�. I am done w/ my account\n",
       "6     churn            FRAUD, for god sake.. What is going on?\n",
       "7     churn    Too expensive!  There should be some discount�.\n",
       "8     churn  My friend told me, there�s a better deal out t...\n",
       "9     churn              Can you believe it? Cancel my account"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>churn</td>\n",
       "      <td>this is interesting� please cancel my policy n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>churn</td>\n",
       "      <td>would you call me ASAP?  My number is 123-555-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>churn</td>\n",
       "      <td>I am not renewing my policy. This is sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>churn</td>\n",
       "      <td>there has been a fraud on my account. please c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>churn</td>\n",
       "      <td>OMG, I don't like this�. I am done w/ my account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>churn</td>\n",
       "      <td>FRAUD, for god sake.. What is going on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>churn</td>\n",
       "      <td>Too expensive!  There should be some discount�.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>churn</td>\n",
       "      <td>My friend told me, there�s a better deal out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>churn</td>\n",
       "      <td>Can you believe it? Cancel my account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>churn</td>\n",
       "      <td>Totally unhappy.. How can I close my policy?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                            message\n",
       "1   churn  this is interesting� please cancel my policy n...\n",
       "2   churn  would you call me ASAP?  My number is 123-555-...\n",
       "3   churn         I am not renewing my policy. This is sucks\n",
       "4   churn  there has been a fraud on my account. please c...\n",
       "5   churn   OMG, I don't like this�. I am done w/ my account\n",
       "6   churn            FRAUD, for god sake.. What is going on?\n",
       "7   churn    Too expensive!  There should be some discount�.\n",
       "8   churn  My friend told me, there�s a better deal out t...\n",
       "9   churn              Can you believe it? Cancel my account\n",
       "10  churn       Totally unhappy.. How can I close my policy?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging the first row\n",
    "sms = sms.loc[1:,:]\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "sms['label_num'] = sms.label.map({'retain':0, 'churn':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>churn</td>\n",
       "      <td>I have enough.. cancelling my policy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>churn</td>\n",
       "      <td>what???</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>retain</td>\n",
       "      <td>I am happy with your service, please renew my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>retain</td>\n",
       "      <td>Auto-renew my policy�.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>retain</td>\n",
       "      <td>Auto-renew my policy, please!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>retain</td>\n",
       "      <td>Jack, what a guy!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>retain</td>\n",
       "      <td>Would you renew my policy?  My policy number i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>retain</td>\n",
       "      <td>Can I renew my policy for another two years?  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>retain</td>\n",
       "      <td>renew my account�. My name is Jane Doe and pho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>churn</td>\n",
       "      <td>I am through, you guys..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message  label_num\n",
       "393   churn               I have enough.. cancelling my policy          1\n",
       "394   churn                                            what???          1\n",
       "395  retain  I am happy with your service, please renew my ...          0\n",
       "396  retain                             Auto-renew my policy�.          0\n",
       "397  retain                     Auto-renew my policy, please!!          0\n",
       "398  retain                                Jack, what a guy!!!          0\n",
       "399  retain  Would you renew my policy?  My policy number i...          0\n",
       "400  retain  Can I renew my policy for another two years?  ...          0\n",
       "401  retain  renew my account�. My name is Jane Doe and pho...          0\n",
       "402   churn                          I am through, you guys..           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "sms.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402,)\n",
      "(402,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = sms.message\n",
    "y = sms.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201,)\n",
      "(201,)\n",
      "(201,)\n",
      "(201,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets for 50:50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert X to vectors\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the vectors to arrays\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 147)\n",
      "(201, 139)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201,)\n",
      "(201,)\n"
     ]
    }
   ],
   "source": [
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "\n",
    "> A recent breakthrough in the field of natural language processing is called word embedding. This is a technique where words are encoded as real-valued vectors in a high-dimensional space, where the similarity between words in terms of meaning translates to closeness in the vector space. Discrete words are mapped to vectors of continuous numbers. This is useful when working with natural language problems with neural networks and deep learning models are we require numbers as input. Keras provides a convenient way to convert positive integer representations of words into a word embedding by an Embedding layer. The layer takes arguments that define the mapping including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value that will be seen as an integer). The layer also allows you to specify the dimensionality for each word vector, called the output dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)\n",
    "MLP is a rudimentary form of artificial neural network algorithm, where I use a simple MLP model with a single hidden layer for illustrative purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we can create our model. We will use an Embedding layer as the input layer, setting the vocabulary to 5,000, the word vector size to 32 dimensions and the input_length to 500. The output of this first layer will be a 32×500 sized matrix.\n",
    "\n",
    "> We will flatten the Embedded layers output to one dimension, then use one dense hidden layer of 250 units with a rectifier activation function. The output layer has one neuron and will use a sigmoid activation to output values of 0 and 1 as predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top_words parameter is set to pick 5000 most used words in whole text dataset\n",
    "top_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words parameter is set to choose the length of each observation (in this case, 500).  \n",
    "# with pad_sequences function, each observation is either padded or truncated to the length of max_works (standardizing for model)\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 500)\n",
      "(201, 500)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201,)\n",
      "(201,)\n"
     ]
    }
   ],
   "source": [
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=128, verbose=2)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN (Convolutional Neural Networks) \n",
    "\n",
    "Convolutional neural networks were designed to process the spatial structure in image data, while being robust to the position and orientation of learned objects in the scene.\n",
    "\n",
    "This same principle can be used on sequences, such as the one-dimensional sequence of words in this SMS data. The same properties that make the CNN model attractive for learning to recognize objects in images can help to learn structure in paragraphs of words, namely the techniques invariance to the specific position of features.\n",
    "\n",
    "Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN \n",
    "import numpy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our convolutional neural network model. This time, after the Embedding input  layer, we insert a Conv1D layer. This convolutional layer has 32 feature maps and reads embedded word representations 3 vector elements of the word embedding at a time.\n",
    "The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "top_words = 5000\n",
    "\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201 samples, validate on 201 samples\n",
      "Epoch 1/5\n",
      "17s - loss: 0.6929 - acc: 0.4876 - val_loss: 0.6899 - val_acc: 0.5622\n",
      "Epoch 2/5\n",
      "0s - loss: 0.6924 - acc: 0.5174 - val_loss: 0.6871 - val_acc: 0.5622\n",
      "Epoch 3/5\n",
      "0s - loss: 0.6860 - acc: 0.5174 - val_loss: 0.6876 - val_acc: 0.6766\n",
      "Epoch 4/5\n",
      "0s - loss: 0.6806 - acc: 0.8209 - val_loss: 0.6847 - val_acc: 0.8358\n",
      "Epoch 5/5\n",
      "0s - loss: 0.6704 - acc: 0.8209 - val_loss: 0.6757 - val_acc: 0.5821\n",
      "Accuracy: 58.21%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "This illustrative python notebook shows how to get started with a simple deep learning techniques utilizing MLP and 1-D CNN. I hope you to see how easy to adopt IBM's Data Science Experience for your data analytics and modeling needs. Please find overview and getting-started information in the Data Science Experience documentation: https://datascience.ibm.com/docs/content/getting-started/welcome-main.html. Learn about Jupyter notebooks, which are used throughout this scenario, in the Data Science Experience documentation: https://datascience.ibm.com/docs/content/analyze-data/notebooks-parent.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6 (Unsupported)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
