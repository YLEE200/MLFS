{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MACHINE LEARING FOR FINANCIAL SERVICES\n",
    "\n",
    "Welcome to MACHINE LEARNING! Below is a simple introductory example of how easy for you to run machine learning algorithms to choose significant feature attributes.\n",
    "\n",
    "\n",
    "## FEATURE SELECTION with KNN and Random Forest\n",
    "Often in machine learning, we have hundreds or even thousands of features and we want a way to create a model that only includes the most relevant features. This has been a typical challenge across all industries including financial services, and with improved machine learning (and deep learning)libraries, the challenge has been effectively mitigated.  Feature selection is basically a process of identifying and selecting a subset of original variables (i.e. features or attributes) to\n",
    "\n",
    "1. Make our model simpler to interpret. \n",
    "1. Reduce the variance of the model, and therefore overfitting. \n",
    "1. Reduce the computational cost and time. \n",
    "\n",
    "The model with the selected features may or may not necessarily gain accuracy of the model, and thus it is important to strike a balance between the above beneifts and its accuracy.\n",
    "\n",
    "The purpose of this notebook is to show simple examples of feature selection methods using KNN and Random Forest, which are common machine learning algorithms that gained their popularity recently, and thus it would be interesting to deploy a couple of ways to perform feature selection from these two.  Especially, Random Forests are often used for feature selection in a data science process. The reason is because the tree-based strategies used by random forests naturally ranks by the features and how well they improve the purity of the node. This means systematic decreases in impurity over all trees (called gini impurity). In addition, there are a couple of more Scikit Learn based feature selection methods included for your reference.\n",
    "\n",
    "> DIMENSIONALITY REDUCITON: in machine learning and statistics, dimensionality reduction is the process of reducing the number of random variables under consideration, via obtaining a set of principal variables. It can be divided into feature selection and feature extraction. Hence, dimensionality reduction is more of a comprehensive terminology for both feature selection and feature extraction\n",
    "\n",
    "> FEATURE EXTRACTION basically transforms the data in the high dimensional space to a lower dimension, as compared to sub-setting a set of significant attributes by feature selection.  The data transformation may be linear or non-linear.  There are a few techniques to perfrom feature extraction such as PCA (Principal Component Analysis).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿TXN_ID</th>\n",
       "      <th>TXN_DT</th>\n",
       "      <th>ACCT_NO</th>\n",
       "      <th>TXN_AMT</th>\n",
       "      <th>ACCT_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>ACCT_TYPE</th>\n",
       "      <th>ATM_IND</th>\n",
       "      <th>TXN_ST</th>\n",
       "      <th>ONLINE_IND</th>\n",
       "      <th>NOLNK_ACCT</th>\n",
       "      <th>FRD_IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123A112</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8350</td>\n",
       "      <td>84.60</td>\n",
       "      <td>1057.46</td>\n",
       "      <td>4.1</td>\n",
       "      <td>REG</td>\n",
       "      <td>0</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123A485</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8379</td>\n",
       "      <td>59.75</td>\n",
       "      <td>1194.94</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123A417</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8402</td>\n",
       "      <td>179.08</td>\n",
       "      <td>3581.58</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123A377</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8406</td>\n",
       "      <td>199.01</td>\n",
       "      <td>3980.22</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123A661</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8409</td>\n",
       "      <td>218.14</td>\n",
       "      <td>4362.75</td>\n",
       "      <td>5.6</td>\n",
       "      <td>REG</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿TXN_ID  TXN_DT   ACCT_NO  TXN_AMT  ACCT_BAL  TENURE ACCT_TYPE  ATM_IND  \\\n",
       "0  123A112  9/9/11  xxxx8350    84.60   1057.46     4.1       REG        0   \n",
       "1  123A485  9/9/11  xxxx8379    59.75   1194.94     5.6       PRM        1   \n",
       "2  123A417  9/9/11  xxxx8402   179.08   3581.58     5.6       PRM        0   \n",
       "3  123A377  9/9/11  xxxx8406   199.01   3980.22     5.6       PRM        0   \n",
       "4  123A661  9/9/11  xxxx8409   218.14   4362.75     5.6       REG        0   \n",
       "\n",
       "  TXN_ST  ONLINE_IND  NOLNK_ACCT  FRD_IND  \n",
       "0     NV           0           0        0  \n",
       "1     OH           0           0        0  \n",
       "2     OH           0           0        0  \n",
       "3     OH           0           0        0  \n",
       "4     OH           0           0        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read a dataset of interest\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/YLEE200/MLFS/master/testdata/FRAUD_SAMPLE1.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "#df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿TXN_ID</th>\n",
       "      <th>TXN_DT</th>\n",
       "      <th>ACCT_NO</th>\n",
       "      <th>TXN_AMT</th>\n",
       "      <th>ACCT_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>ACCT_TYPE</th>\n",
       "      <th>ATM_IND</th>\n",
       "      <th>TXN_ST</th>\n",
       "      <th>ONLINE_IND</th>\n",
       "      <th>NOLNK_ACCT</th>\n",
       "      <th>FRD_IND</th>\n",
       "      <th>ST_NO</th>\n",
       "      <th>ACCT_TIER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123A112</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8350</td>\n",
       "      <td>84.60</td>\n",
       "      <td>1057.46</td>\n",
       "      <td>4.1</td>\n",
       "      <td>REG</td>\n",
       "      <td>0</td>\n",
       "      <td>NV</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123A485</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8379</td>\n",
       "      <td>59.75</td>\n",
       "      <td>1194.94</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123A417</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8402</td>\n",
       "      <td>179.08</td>\n",
       "      <td>3581.58</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123A377</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8406</td>\n",
       "      <td>199.01</td>\n",
       "      <td>3980.22</td>\n",
       "      <td>5.6</td>\n",
       "      <td>PRM</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123A661</td>\n",
       "      <td>9/9/11</td>\n",
       "      <td>xxxx8409</td>\n",
       "      <td>218.14</td>\n",
       "      <td>4362.75</td>\n",
       "      <td>5.6</td>\n",
       "      <td>REG</td>\n",
       "      <td>0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿TXN_ID  TXN_DT   ACCT_NO  TXN_AMT  ACCT_BAL  TENURE ACCT_TYPE  ATM_IND  \\\n",
       "0  123A112  9/9/11  xxxx8350    84.60   1057.46     4.1       REG        0   \n",
       "1  123A485  9/9/11  xxxx8379    59.75   1194.94     5.6       PRM        1   \n",
       "2  123A417  9/9/11  xxxx8402   179.08   3581.58     5.6       PRM        0   \n",
       "3  123A377  9/9/11  xxxx8406   199.01   3980.22     5.6       PRM        0   \n",
       "4  123A661  9/9/11  xxxx8409   218.14   4362.75     5.6       REG        0   \n",
       "\n",
       "  TXN_ST  ONLINE_IND  NOLNK_ACCT  FRD_IND  ST_NO  ACCT_TIER  \n",
       "0     NV           0           0        0      1          1  \n",
       "1     OH           0           0        0      0          0  \n",
       "2     OH           0           0        0      0          0  \n",
       "3     OH           0           0        0      0          0  \n",
       "4     OH           0           0        0      0          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's map following into a numerical format\n",
    "\n",
    "df['ST_NO'] = df.TXN_ST.map({'OH': 0, 'NV': 1})\n",
    "df['ACCT_TIER'] = df.ACCT_TYPE.map({'PRM': 0,'REG': 1})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numeric feature variables \n",
    "\n",
    "feature_cols = [\n",
    "    'TXN_AMT',\n",
    "    'ACCT_BAL',\n",
    "    'TENURE',\n",
    "    'ATM_IND',\n",
    "    'ONLINE_IND',\n",
    "    'NOLNK_ACCT',\n",
    "    'ST_NO',\n",
    "    'ACCT_TIER'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXN_AMT</th>\n",
       "      <th>ACCT_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>ATM_IND</th>\n",
       "      <th>ONLINE_IND</th>\n",
       "      <th>NOLNK_ACCT</th>\n",
       "      <th>ST_NO</th>\n",
       "      <th>ACCT_TIER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.60</td>\n",
       "      <td>1057.46</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.75</td>\n",
       "      <td>1194.94</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179.08</td>\n",
       "      <td>3581.58</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199.01</td>\n",
       "      <td>3980.22</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218.14</td>\n",
       "      <td>4362.75</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>254.52</td>\n",
       "      <td>5090.46</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>275.18</td>\n",
       "      <td>5503.63</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>294.96</td>\n",
       "      <td>5899.26</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>299.55</td>\n",
       "      <td>5991.01</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>316.49</td>\n",
       "      <td>6329.73</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TXN_AMT  ACCT_BAL  TENURE  ATM_IND  ONLINE_IND  NOLNK_ACCT  ST_NO  \\\n",
       "0    84.60   1057.46     4.1        0           0           0      1   \n",
       "1    59.75   1194.94     5.6        1           0           0      0   \n",
       "2   179.08   3581.58     5.6        0           0           0      0   \n",
       "3   199.01   3980.22     5.6        0           0           0      0   \n",
       "4   218.14   4362.75     5.6        0           0           0      0   \n",
       "5   254.52   5090.46     5.6        1           0           0      0   \n",
       "6   275.18   5503.63     5.6        1           0           0      0   \n",
       "7   294.96   5899.26     5.6        1           0           0      0   \n",
       "8   299.55   5991.01     2.5        1           0           0      1   \n",
       "9   316.49   6329.73     5.6        1           0           0      0   \n",
       "\n",
       "   ACCT_TIER  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "5          0  \n",
       "6          0  \n",
       "7          1  \n",
       "8          1  \n",
       "9          0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a few numerical feature attributes for this demo (feature variables should be numeric)\n",
    "\n",
    "X = df[feature_cols]\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a response vector 'y' by selecting a Series\n",
    "y = df.FRD_IND\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### KNN Model Traing with all numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instanstiate a KNN model with the above features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# making prediction on test data\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### KNN Feature Selection with KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TENURE', 'ONLINE_IND', 'ST_NO']\n"
     ]
    }
   ],
   "source": [
    "# selecting important feature variables with KBest\n",
    "# you can change k value to choose different number of features\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "\n",
    "select = SelectKBest(k=3)\n",
    "select_features = select.fit(X_train, y_train)\n",
    "\n",
    "indices_selected = select.get_support(indices = True)\n",
    "colnames_selected = [X.columns[i] for i in indices_selected]\n",
    "\n",
    "print (colnames_selected)\n",
    "\n",
    "X_sel = X.loc[:, colnames_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets with test size is 40%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the training set\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: make predictions on the testing set\n",
    "\n",
    "y_pred_sel = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901639344262\n",
      "0.909836065574\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values from selected features (y_pred_sel)\n",
    "print(metrics.accuracy_score(y_test, y_pred_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very minimal difference in the accuracies between the model with whole set of features and the one with selected features.  This could be definitely worthwhile if you have to deal with a large amount of feature dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Random Forest Model Training with all numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into 40% test and 60% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TXN_AMT', 0.25079387077627319)\n",
      "('ACCT_BAL', 0.26357109949620766)\n",
      "('TENURE', 0.24299377592804486)\n",
      "('ATM_IND', 0.034699731221416293)\n",
      "('ONLINE_IND', 0.033992949227551965)\n",
      "('NOLNK_ACCT', 0.080703091196977675)\n",
      "('ST_NO', 0.077348075629225271)\n",
      "('ACCT_TIER', 0.015897406524303024)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feature_cols, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Ranom Forest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=0.2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.2\n",
    "sfm = SelectFromModel(clf, threshold=0.2)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXN_AMT\n",
      "ACCT_BAL\n",
      "TENURE\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feature_cols[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92213114754098358"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (14 Features) Model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88934426229508201"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (3 Features) Model\n",
    "accuracy_score(y_test, y_important_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the accuracy scores, our original model which contained all 8 features is 92% accurate while the our 'limited' model which contained only three features is 89% accurate. Thus, for a very small cost in accuracy we greatly reduced the number of features in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something Extra\n",
    "There are a couple of more Scikit Learn based feature selections... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Recursive Feature Elimination (RFE) method ...\n",
    "is a feature selection approach. It works by recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ONLINE_IND', 'NOLNK_ACCT', 'ST_NO']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "indices_selected = rfe.get_support(indices = True)\n",
    "colnames_selected = [X.columns[i] for i in indices_selected]\n",
    "\n",
    "print (colnames_selected)\n",
    "\n",
    "X_sel = X.loc[:, colnames_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit Learn also has...\n",
    "methods that use ensembles of decision trees (like Random Forest or Extra Trees) can also compute the relative importance of each attribute. These importance values can be used to inform a feature selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TXN_AMT', 0.27760386284717614)\n",
      "('ACCT_BAL', 0.26035591122344121)\n",
      "('TENURE', 0.22769266122335349)\n",
      "('ATM_IND', 0.03283368711922259)\n",
      "('ONLINE_IND', 0.046818290225637674)\n",
      "('NOLNK_ACCT', 0.0717727440717046)\n",
      "('ST_NO', 0.063003159915584819)\n",
      "('ACCT_TIER', 0.019919683373879393)\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "#print(model.feature_importances_)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feature_cols, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SUMMARY\n",
    "This illustrative python notebook shows how to run KNN and Random Forest to do feature selection. I hope you to see how easy to adopt machine learning for your data analytics and modeling needs.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
