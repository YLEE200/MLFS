{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPM (Other People's Machine)\n",
    "### ... learning libraries\n",
    "\n",
    "Well, it is not about Other People's Money that I am talking about here.  There are many open source libraries available, including Deep Learning libraries that you can call in for your rather complex ANN models.  Why not we do the OPM for ANN?  \n",
    "\n",
    "In this notebook, let me provide you with a deep learning example with another popular neural network library, Keras for predicting credit default (or write-off) using credit payment sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "> from [wikipedia](https://en.wikipedia.org/wiki/Keras)\n",
    "\n",
    "Keras is an open source neural network library written in Python. It is capable of running on top of MXNet, Deeplearning4j, Tensorflow, CNTK or Theano. Designed to enable fast experimentation with deep neural networks, it focuses on being minimal, modular and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System), and its primary author and maintainer is François Chollet, a Google engineer.\n",
    "\n",
    "In 2017, Google's TensorFlow team decided to support Keras in TensorFlow's core library. Chollet explained that Keras was conceived to be an interface rather than an end-to-end machine-learning framework. It presents a higher-level, more intuitive set of abstractions that make it easy to configure neural networks regardless of the backend scientific computing library. Microsoft has been working to add a CNTK backend to Keras as well and the functionality is currently in beta release with CNTK v2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <th>PROD</th>\n",
       "      <th>CURR_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>CUST_INC</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>PMT_DUE</th>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <th>FICO_SCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>755.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44212</td>\n",
       "      <td>46</td>\n",
       "      <td>60.41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1292</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>276.61</td>\n",
       "      <td>0.7</td>\n",
       "      <td>86249</td>\n",
       "      <td>34</td>\n",
       "      <td>22.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1293</td>\n",
       "      <td>2.GOLD</td>\n",
       "      <td>424.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79474</td>\n",
       "      <td>45</td>\n",
       "      <td>21.23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294</td>\n",
       "      <td>3.PLAT</td>\n",
       "      <td>11683.23</td>\n",
       "      <td>10.8</td>\n",
       "      <td>81198</td>\n",
       "      <td>58</td>\n",
       "      <td>584.16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>246.34</td>\n",
       "      <td>5.5</td>\n",
       "      <td>63502</td>\n",
       "      <td>35</td>\n",
       "      <td>19.71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ACCT_NO    PROD  CURR_BAL  TENURE  CUST_INC  CUST_AGE  PMT_DUE  NO_DM_CNT  \\\n",
       "0      1291   1.REG    755.16     3.0     44212        46    60.41          5   \n",
       "1      1292   1.REG    276.61     0.7     86249        34    22.13         10   \n",
       "2      1293  2.GOLD    424.70     0.1     79474        45    21.23         22   \n",
       "3      1294  3.PLAT  11683.23    10.8     81198        58   584.16         22   \n",
       "4      1295   1.REG    246.34     5.5     63502        35    19.71         11   \n",
       "\n",
       "   WRITE_OFF_IND  FICO_SCR  \n",
       "0              1       651  \n",
       "1              0       702  \n",
       "2              0       753  \n",
       "3              0       763  \n",
       "4              1       590  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read a dataset of interest\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/YLEE200/MLFS/master/testdata/CRPMT_SAMPLE.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <td>610</td>\n",
       "      <td>1595.500000</td>\n",
       "      <td>176.236111</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>1443.2500</td>\n",
       "      <td>1595.500</td>\n",
       "      <td>1747.7500</td>\n",
       "      <td>1900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CURR_BAL</th>\n",
       "      <td>610</td>\n",
       "      <td>1804.107770</td>\n",
       "      <td>2905.286132</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>331.7525</td>\n",
       "      <td>680.625</td>\n",
       "      <td>1049.4625</td>\n",
       "      <td>11996.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TENURE</th>\n",
       "      <td>610</td>\n",
       "      <td>6.432459</td>\n",
       "      <td>4.634506</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>5.900</td>\n",
       "      <td>8.9000</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_INC</th>\n",
       "      <td>610</td>\n",
       "      <td>83260.531148</td>\n",
       "      <td>42206.490438</td>\n",
       "      <td>25089.0</td>\n",
       "      <td>54015.5000</td>\n",
       "      <td>73585.500</td>\n",
       "      <td>94804.2500</td>\n",
       "      <td>217338.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_AGE</th>\n",
       "      <td>610</td>\n",
       "      <td>40.132787</td>\n",
       "      <td>11.691593</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>69.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PMT_DUE</th>\n",
       "      <td>610</td>\n",
       "      <td>99.196262</td>\n",
       "      <td>142.255957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.6625</td>\n",
       "      <td>46.400</td>\n",
       "      <td>78.4625</td>\n",
       "      <td>599.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <td>610</td>\n",
       "      <td>9.870492</td>\n",
       "      <td>6.714781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <td>610</td>\n",
       "      <td>0.150820</td>\n",
       "      <td>0.358167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FICO_SCR</th>\n",
       "      <td>610</td>\n",
       "      <td>701.326230</td>\n",
       "      <td>85.151137</td>\n",
       "      <td>551.0</td>\n",
       "      <td>625.0000</td>\n",
       "      <td>693.500</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>849.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean           std      min         25%  \\\n",
       "﻿ACCT_NO         610   1595.500000    176.236111   1291.0   1443.2500   \n",
       "CURR_BAL         610   1804.107770   2905.286132    -25.0    331.7525   \n",
       "TENURE           610      6.432459      4.634506      0.1      2.8000   \n",
       "CUST_INC         610  83260.531148  42206.490438  25089.0  54015.5000   \n",
       "CUST_AGE         610     40.132787     11.691593     19.0     31.0000   \n",
       "PMT_DUE          610     99.196262    142.255957      0.0     22.6625   \n",
       "NO_DM_CNT        610      9.870492      6.714781      1.0      4.0000   \n",
       "WRITE_OFF_IND    610      0.150820      0.358167      0.0      0.0000   \n",
       "FICO_SCR         610    701.326230     85.151137    551.0    625.0000   \n",
       "\n",
       "                     50%         75%        max  \n",
       "﻿ACCT_NO        1595.500   1747.7500    1900.00  \n",
       "CURR_BAL         680.625   1049.4625   11996.61  \n",
       "TENURE             5.900      8.9000      22.00  \n",
       "CUST_INC       73585.500  94804.2500  217338.00  \n",
       "CUST_AGE          40.000     49.0000      69.00  \n",
       "PMT_DUE           46.400     78.4625     599.83  \n",
       "NO_DM_CNT          7.000     15.0000      26.00  \n",
       "WRITE_OFF_IND      0.000      0.0000       1.00  \n",
       "FICO_SCR         693.500    780.0000     849.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Labeling and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿ACCT_NO</th>\n",
       "      <th>PROD</th>\n",
       "      <th>CURR_BAL</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>CUST_INC</th>\n",
       "      <th>CUST_AGE</th>\n",
       "      <th>PMT_DUE</th>\n",
       "      <th>NO_DM_CNT</th>\n",
       "      <th>WRITE_OFF_IND</th>\n",
       "      <th>FICO_SCR</th>\n",
       "      <th>PROD_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>755.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44212</td>\n",
       "      <td>46</td>\n",
       "      <td>60.41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1292</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>276.61</td>\n",
       "      <td>0.7</td>\n",
       "      <td>86249</td>\n",
       "      <td>34</td>\n",
       "      <td>22.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1293</td>\n",
       "      <td>2.GOLD</td>\n",
       "      <td>424.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79474</td>\n",
       "      <td>45</td>\n",
       "      <td>21.23</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294</td>\n",
       "      <td>3.PLAT</td>\n",
       "      <td>11683.23</td>\n",
       "      <td>10.8</td>\n",
       "      <td>81198</td>\n",
       "      <td>58</td>\n",
       "      <td>584.16</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295</td>\n",
       "      <td>1.REG</td>\n",
       "      <td>246.34</td>\n",
       "      <td>5.5</td>\n",
       "      <td>63502</td>\n",
       "      <td>35</td>\n",
       "      <td>19.71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿ACCT_NO    PROD  CURR_BAL  TENURE  CUST_INC  CUST_AGE  PMT_DUE  NO_DM_CNT  \\\n",
       "0      1291   1.REG    755.16     3.0     44212        46    60.41          5   \n",
       "1      1292   1.REG    276.61     0.7     86249        34    22.13         10   \n",
       "2      1293  2.GOLD    424.70     0.1     79474        45    21.23         22   \n",
       "3      1294  3.PLAT  11683.23    10.8     81198        58   584.16         22   \n",
       "4      1295   1.REG    246.34     5.5     63502        35    19.71         11   \n",
       "\n",
       "   WRITE_OFF_IND  FICO_SCR  PROD_NO  \n",
       "0              1       651        0  \n",
       "1              0       702        0  \n",
       "2              0       753        1  \n",
       "3              0       763        2  \n",
       "4              1       590        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# converting PROD to numerical (0: 1.REG, 1: 2.GOLD, 2: 3.PLAT)\n",
    "lenc = LabelEncoder()\n",
    "lenc.fit(df['PROD'])\n",
    "\n",
    "df['PROD_NO'] = lenc.transform(df['PROD'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all numeric feature variables \n",
    "\n",
    "feature_cols = [\n",
    "    'CURR_BAL',                                               \n",
    "    'TENURE',                       \n",
    "    'CUST_INC',                      \n",
    "    'CUST_AGE',                                \n",
    "    'PMT_DUE',                                               \n",
    "    'NO_DM_CNT',               \n",
    "    'FICO_SCR',\n",
    "    'PROD_NO'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CURR_BAL     float64\n",
       "TENURE       float64\n",
       "CUST_INC       int64\n",
       "CUST_AGE       int64\n",
       "PMT_DUE      float64\n",
       "NO_DM_CNT      int64\n",
       "FICO_SCR       int64\n",
       "PROD_NO        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_cols]\n",
    "y = df.WRITE_OFF_IND\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Neural Networks is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results. There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and Performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a simple model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(set(y)), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process will run for a fixed number of iterations through the dataset called epochs, that we must specify using the nepochs argument. We can also set the number of instances that are evaluated before a weight update in the network is performed, called the batch size and set using the batch_size argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "epoch = 50\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "488/488 [==============================] - 0s - loss: 0.4814 - acc: 0.7828     \n",
      "Epoch 2/50\n",
      "488/488 [==============================] - 0s - loss: 0.3738 - acc: 0.8627     \n",
      "Epoch 3/50\n",
      "488/488 [==============================] - 0s - loss: 0.3724 - acc: 0.8586     \n",
      "Epoch 4/50\n",
      "488/488 [==============================] - 0s - loss: 0.3799 - acc: 0.8627     \n",
      "Epoch 5/50\n",
      "488/488 [==============================] - 0s - loss: 0.3553 - acc: 0.8566     \n",
      "Epoch 6/50\n",
      "488/488 [==============================] - 0s - loss: 0.3597 - acc: 0.8566     \n",
      "Epoch 7/50\n",
      "488/488 [==============================] - 0s - loss: 0.3437 - acc: 0.8545     \n",
      "Epoch 8/50\n",
      "488/488 [==============================] - 0s - loss: 0.3339 - acc: 0.8586     \n",
      "Epoch 9/50\n",
      "488/488 [==============================] - 0s - loss: 0.3570 - acc: 0.8525     \n",
      "Epoch 10/50\n",
      "488/488 [==============================] - 0s - loss: 0.3439 - acc: 0.8607     \n",
      "Epoch 11/50\n",
      "488/488 [==============================] - 0s - loss: 0.3395 - acc: 0.8627     \n",
      "Epoch 12/50\n",
      "488/488 [==============================] - 0s - loss: 0.3237 - acc: 0.8607     \n",
      "Epoch 13/50\n",
      "488/488 [==============================] - 0s - loss: 0.3337 - acc: 0.8545     \n",
      "Epoch 14/50\n",
      "488/488 [==============================] - 0s - loss: 0.3463 - acc: 0.8607     \n",
      "Epoch 15/50\n",
      "488/488 [==============================] - 0s - loss: 0.3404 - acc: 0.8709     \n",
      "Epoch 16/50\n",
      "488/488 [==============================] - 0s - loss: 0.3165 - acc: 0.8545     \n",
      "Epoch 17/50\n",
      "488/488 [==============================] - 0s - loss: 0.3100 - acc: 0.8668     \n",
      "Epoch 18/50\n",
      "488/488 [==============================] - 0s - loss: 0.3581 - acc: 0.8525     \n",
      "Epoch 19/50\n",
      "488/488 [==============================] - 0s - loss: 0.3281 - acc: 0.8525     \n",
      "Epoch 20/50\n",
      "488/488 [==============================] - 0s - loss: 0.3343 - acc: 0.8586     \n",
      "Epoch 21/50\n",
      "488/488 [==============================] - 0s - loss: 0.3066 - acc: 0.8689     \n",
      "Epoch 22/50\n",
      "488/488 [==============================] - 0s - loss: 0.3085 - acc: 0.8709     \n",
      "Epoch 23/50\n",
      "488/488 [==============================] - 0s - loss: 0.3146 - acc: 0.8627     \n",
      "Epoch 24/50\n",
      "488/488 [==============================] - 0s - loss: 0.3222 - acc: 0.8566     \n",
      "Epoch 25/50\n",
      "488/488 [==============================] - 0s - loss: 0.3235 - acc: 0.8668     \n",
      "Epoch 26/50\n",
      "488/488 [==============================] - 0s - loss: 0.3064 - acc: 0.8750     \n",
      "Epoch 27/50\n",
      "488/488 [==============================] - 0s - loss: 0.3199 - acc: 0.8689     \n",
      "Epoch 28/50\n",
      "488/488 [==============================] - 0s - loss: 0.3203 - acc: 0.8791     \n",
      "Epoch 29/50\n",
      "488/488 [==============================] - 0s - loss: 0.3235 - acc: 0.8525     \n",
      "Epoch 30/50\n",
      "488/488 [==============================] - 0s - loss: 0.3341 - acc: 0.8668     \n",
      "Epoch 31/50\n",
      "488/488 [==============================] - 0s - loss: 0.3038 - acc: 0.8648     \n",
      "Epoch 32/50\n",
      "488/488 [==============================] - 0s - loss: 0.2914 - acc: 0.8852     \n",
      "Epoch 33/50\n",
      "488/488 [==============================] - 0s - loss: 0.3220 - acc: 0.8730     \n",
      "Epoch 34/50\n",
      "488/488 [==============================] - 0s - loss: 0.3257 - acc: 0.8566     \n",
      "Epoch 35/50\n",
      "488/488 [==============================] - 0s - loss: 0.3181 - acc: 0.8668     \n",
      "Epoch 36/50\n",
      "488/488 [==============================] - 0s - loss: 0.3308 - acc: 0.8770     \n",
      "Epoch 37/50\n",
      "488/488 [==============================] - 0s - loss: 0.3090 - acc: 0.8566     \n",
      "Epoch 38/50\n",
      "488/488 [==============================] - 0s - loss: 0.3158 - acc: 0.8586     \n",
      "Epoch 39/50\n",
      "488/488 [==============================] - 0s - loss: 0.2954 - acc: 0.8791     \n",
      "Epoch 40/50\n",
      "488/488 [==============================] - 0s - loss: 0.3212 - acc: 0.8566     \n",
      "Epoch 41/50\n",
      "488/488 [==============================] - 0s - loss: 0.3069 - acc: 0.8586     \n",
      "Epoch 42/50\n",
      "488/488 [==============================] - 0s - loss: 0.2993 - acc: 0.8709     \n",
      "Epoch 43/50\n",
      "488/488 [==============================] - 0s - loss: 0.3119 - acc: 0.8689     \n",
      "Epoch 44/50\n",
      "488/488 [==============================] - 0s - loss: 0.2779 - acc: 0.8709     \n",
      "Epoch 45/50\n",
      "488/488 [==============================] - 0s - loss: 0.3230 - acc: 0.8730     \n",
      "Epoch 46/50\n",
      "488/488 [==============================] - 0s - loss: 0.2982 - acc: 0.8750     \n",
      "Epoch 47/50\n",
      "488/488 [==============================] - 0s - loss: 0.3137 - acc: 0.8648     \n",
      "Epoch 48/50\n",
      "488/488 [==============================] - 0s - loss: 0.2994 - acc: 0.8730     \n",
      "Epoch 49/50\n",
      "488/488 [==============================] - 0s - loss: 0.3025 - acc: 0.8730     \n",
      "Epoch 50/50\n",
      "488/488 [==============================] - 0s - loss: 0.2949 - acc: 0.8689     \n",
      " 10/122 [=>............................] - ETA: 0s\n",
      "acc: 80.33%\n"
     ]
    }
   ],
   "source": [
    "# make y to class variables\n",
    "one_hot_label_y_train = np_utils.to_categorical(y_train)\n",
    "one_hot_label_y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# model training and evaluation\n",
    "model.fit(X_train, one_hot_label_y_train, epochs=epoch, batch_size=batch_size)\n",
    "score = model.evaluate(X_test, one_hot_label_y_test, batch_size=batch_size)\n",
    "\n",
    "print(\"\\n{}: {:.2f}%\".format(model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5003066 , -0.53785823, -0.18407372,  0.60715339, -0.57826074,\n",
       "        0.47208358,  0.67581671,  0.44874886])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample X test data observation 2, scaled\n",
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample y test data observation 2, tuple\n",
    "one_hot_label_y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting y value, observation 2\n",
    "predict_data = np.array(X_test[1])\n",
    "x = predict_data.reshape(-1,8)\n",
    "\n",
    "predict = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98823136,  0.01176866]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The prediction is \"no write-off\" as close to the actual y label of [1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "This illustrative python notebook shows how to run a simple deep learning technique from Keras library. I hope you to see how easy to adopt deep learning for your data analytics and modeling needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
